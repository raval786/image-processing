{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optical flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect 10 corners and track those\n",
    "corner_track_params = dict(maxCorners = 10,qualityLevel=0.3,minDistance=7,blockSize=7) \n",
    "# maxCorners is that how many corners we want to detect the quality one\n",
    "# qualityLevel, minDistance, minDistance this are default values wecan tune them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lk_params is lucas kanade optical flow function\n",
    "lk_params = dict(winSize=(200,200), maxLevel = 2, criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10,0.03))\n",
    "# winsize=(200,200)is trad of if choose small window size it too much noise to track them and we can't detect larger motion but if we choose larger winsize we can't detect small motion\n",
    "\n",
    "# maxLevel is lucas kanade algorithm use the image pyramid method it allow us to find optical flow at various resolution of image \n",
    "# ex. Level 0 is orignal image \n",
    "# Level 1 is 1/2 resolution image\n",
    "# Level 2 is 1/4 resolution image\n",
    "# Level 3 is 1/8 resolution image\n",
    "# Level 4 is 1/16 resolution image\n",
    "\n",
    "# criteria IS we are providing two criteria to perform lucas kanade optical flow, we providing maximum no. of iteration\n",
    "# and 10 is for cv2.TERM_CRITIERIA_COUNT. and 0.03 is for cv2.TERM_CRITERIA_EPS. EPS means episolon\n",
    "# more iteration means more exhaustive search for the points\n",
    "# so that's to do if the counts on how many iteration are you going to be looking for these points in current frame vs the prevoius frame\n",
    "# what these does it exchanging speed of your tracking vs the accuracy of your tracking\n",
    "# 10,0.03 is we have to tune for our video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "ret, prev_frame = cap.read()\n",
    "\n",
    "prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# POINTS TO TRACK\n",
    "prevPts = cv2.goodFeaturesToTrack(prev_gray,mask=None, **corner_track_params) # we have to put **before the corner_track_params because it is how put dictionary ito the function\n",
    "\n",
    "# actual drawing line in video then tracking points\n",
    "mask = np.zeros_like(prev_frame)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, frame = cap.read() # frame is the currnet frame\n",
    "    \n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    nextPts, status, err = cv2.calcOpticalFlowPyrLK(prev_gray,frame_gray,prevPts,None,**lk_params) # cv2.calcOpticalFlowPyrLK in PyrLK is lucas kanade pyramid\n",
    "    \n",
    "    # status will return status array\n",
    "    # it output what known as a status vector where each element of the vector is set to one if the flow for the corresponding features has been found otherwise it set to zero\n",
    "    \n",
    "    good_new = nextPts[status==1]\n",
    "    good_prev = prevPts[status==1] # matching them up based on the index location\n",
    "    # status vector is set to 1 if the flow for the corresponding features has been found\n",
    "    # essentially this is connecting where the prevoius points were to the next set of points\n",
    "    \n",
    "    for i, (new,prev) in enumerate(zip(good_new,good_prev)):\n",
    "        \n",
    "        x_new, y_new = new.ravel()\n",
    "        x_prev, y_prev = prev.ravel()\n",
    "        \n",
    "        # Lines will be drawn using the mask created from the first frame\n",
    "        mask = cv2.line(mask, (x_new,y_new), (x_prev,y_prev),(0,255,0),3)\n",
    "        \n",
    "        # Draw red circles at corner points\n",
    "        frame = cv2.circle(frame,(x_new,y_new),8,(0,0,255),-1)\n",
    "        \n",
    "    img = cv2.add(frame,mask)\n",
    "    cv2.imshow('tracking',img)\n",
    "    \n",
    "    k = cv2.waitKey(30) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "    # now we have to update the current frame to be the prevoius frame for next iteration\n",
    "    prev_gray = frame_gray.copy()\n",
    "    prevPts = good_new.reshape(-1,1,2) # we have to reshpae good_new.reshape(-1,1,2) this because this way cv2.calcOpticalFlowPyrLK this function accept\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense Optical Flow in OpenCV\n",
    "\n",
    "calcOpticalFlowFarneback(prev, next, flow, pyr_scale, levels, winsize, iterations, poly_n, poly_sigma, flags) -> flow\n",
    "\n",
    "This function computes a dense optical flow using the Gunnar Farneback's algorithm.\n",
    "\n",
    "Here are the parameters for the function and what they represen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* prev first 8-bit single-channel input image.\n",
    "* next second input image of the same size and the same type as prev.\n",
    "* flow computed flow image that has the same size as prev and type CV_32FC2.\n",
    "* pyr_scale parameter, specifying the image scale (\\<1) to build pyramids for each image\n",
    "    * pyr_scale=0.5 means a classical pyramid, where each next layer is twice smaller than the previous one.\n",
    "    \n",
    "* levels number of pyramid layers including the initial image; levels=1 means that no extra layers are created and only the original images are used.\n",
    "* winsize averaging window size\n",
    "    * larger values increase the algorithm robustness to image\n",
    "* noise and give more chances for fast motion detection, but yield more blurred motion field.\n",
    "* iterations number of iterations the algorithm does at each pyramid level.\n",
    "* poly_n size of the pixel neighborhood used to find polynomial expansion in each pixel\n",
    "    * larger values mean that the image will be approximated with smoother surfaces, yielding more robust algorithm and more blurred motion field, typically poly_n =5 or 7.\n",
    "* poly_sigma standard deviation of the Gaussian that is used to smooth derivatives used as a basis for the polynomial expansion; for poly_n=5, you can set poly_sigma=1.1, for poly_n=7, a good value would be poly_sigma=1.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "\n",
    "prevsImg = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "hsv_mask = np.zeros_like(frame1)\n",
    "hsv_mask[:,:,1] = 255 # hsv is hue stauration value\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, frame2 = cap.read()\n",
    "    \n",
    "    nextImg = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # calulate the optical flow\n",
    "    # REFER BOOK IN THAT ALL THE DETAILS ARE WRITTEN\n",
    "    flow = cv2.calcOpticalFlowFarneback(prevsImg,nextImg,None,0.5,3,15,3,5,1.2,0) # default parameter\n",
    "    \n",
    "    mag, ang = cv2.cartToPolar(flow[:,:,0],flow[:,:,1],angleInDegrees=True) # cartigian cooridinate for vectoers\n",
    "    # flow[:,:,0] for every pixel in x and y choose horizontal(0)\n",
    "    # flow[:,:,1] for every pixel in x and y choose vertical(0)\n",
    "    hsv_mask[:,:,0] = ang/2\n",
    "    # hsv_mask[:,:,0] for all pixels we grab the hue\n",
    "    # ang/2 this way we don't get so many hues and we actual looks half the hues it help distinguishinfo on left right up down a little clear so essemtially 360 degree from 180\n",
    "    hsv_mask[:,:,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "    # hsv_mask[:,:,2]it grab the actual values\n",
    "    # to find the value based on the magnitude\n",
    "    bgr = cv2.cvtColor(hsv_mask,cv2.COLOR_HSV2BGR)\n",
    "    cv2.imshow('frame',bgr)\n",
    "    \n",
    "    k = cv2.waitKey(10) & 0xFF\n",
    "    \n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "    prevsImg =nextImg\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
